{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3 - 4/9 - Data collection and manipulation\n",
    "\n",
    "## I will try to set up a private github repository to share with you, it will have all the lecture notes in ipynb format, where you can try out the codes and modify yourself. I am still working on that and may need your github account. The codes only provide a foudation, the key is to change around the code to see what the different codes do. \n",
    "\n",
    "### Reminder: Professor's office hour: Tuesday from 2 - 4pm\n",
    "### Hws are due on GS, the jupytor notebook (ipynb file) should be able to run from top to bottom without error to receive credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shell commands\n",
    "\n",
    "## Useful Shell Commands for Text Files\n",
    "\n",
    "### Voice operation using text command, not for coding\n",
    "\n",
    "ex: terminal in jupyterhub (review lab1)\n",
    "\n",
    "- `cat`: prints content of a file\n",
    "    - ex: `cat README.md` will print out the full file in txt format\n",
    "- `head`: prints first few lines of a file\n",
    "- `sed`: (stream editor) changes texts\n",
    "- `paste`: pasts text files side-by-side\n",
    "- `cut`: processes columns in delimited text file\n",
    "- `find`: searches file system\n",
    "- `grep`: searches text given regular expression pattern\n",
    "- Many more!\n",
    "\n",
    "## References to learn shell command line\n",
    "\n",
    "- Unix Shell: [Software Carpentry Lessons](https://software-carpentry.org/lessons/)\n",
    "- [Unix Power Tools](https://ucsb-primo.hosted.exlibrisgroup.com/primo-explore/fulldisplay?docid=01UCSB_ALMA51295276690003776&context=L&vid=UCSB&search_scope=default_scope&tab=default_tab&lang=en_US)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File download\n",
    "\n",
    "\"Dummy Way\" download the csv file from website and upload to github, then pull it to the jupyter hub.\n",
    "\n",
    "Sometimes URL of a csv file is directly visible (e.g., Github). In these cases, `wget` is simple but effective. Take https://github.com/fivethirtyeight/data for example. There are many csv files in this repository, and when you browse a file, you see a button named \"raw\". Without clicking on \"raw\" you will see a nice looking table.\n",
    "\n",
    "Take the candy ratings data: https://github.com/fivethirtyeight/data/tree/master/candy-power-ranking. Using `wget` it is easy to download the file to course jupyterhub. After running the command you will be able to see the dataset in your jupyterhub. Also you can run it in the terminal using shell command. By using `%%bash` you can skip the shell command in the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://raw.githubusercontent.com/fivethirtyeight/data/master/candy-power-ranking/candy-data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing file contents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head candy-data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head candy-data.csv ## also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n 1 candy-data.csv  ## first line is the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wc -l candy-data.csv      ## counts lines in text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cut -d',' -f1,3 candy-data.csv    ## prints columns of delimited text, try different numbers than 1 and 3,\n",
    "## ex: 1-3 will print out column 1, 2, and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! grep 'Tootsie' candy-data.csv      ## finds lines with pattern (regular expression)\n",
    "## neat way to search around key words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining commands togeter\n",
    "\n",
    "The power of command lines is unleashed when you chain commands together. You can achieve this by using \"pipes\". \n",
    "Many commands in the shell sends output to what is called \"stdout\" (essentially printing to screen). What enables pipes is to receive input from \"stdin\" (standard input).\n",
    "\n",
    "Hence, we can make commands such as the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n1 candy-data.csv #prints first line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n1 candy-data.csv | sed 's/,/\\n/g' # placing a line break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n1 candy-data.csv | sed 's/,/\\n/g' | sed 's/chocolate/CHOCOLATE/g' #placing a line break and Capitalize \"chocolate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text file search and manipulation\n",
    "\n",
    "Comands like `grep`, `sed` and `awk` enable on-the-fly text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#if trying to understand the command, to go explain shell and paste the entire command\n",
    "#This requries you to add the line one by one to see the effect the commands do.\n",
    "wget -O - https://www.irs.gov/statistics/soi-tax-stats-individual-income-tax-statistics-zip-code-data-soi \\ \n",
    "    | grep 'zipcode.zip' \\ # print som string but still with other garbage\n",
    "    | sed 's/<a data/\\n<a data/g' \\ #additional new lines to see better\n",
    "    | grep -Po '(?<=href=\")[^\"]*(?=\")'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shell and Jupyter\n",
    "\n",
    "Shell and Jupyter can be used together, and this becomes even more interesting.\n",
    "\n",
    "We can do things such as download all files with `zipcode.zip` file ending by first grabbing all such file names from the html page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = !wget -q -O - https://www.irs.gov/statistics/soi-tax-stats-individual-income-tax-statistics-zip-code-data-soi | grep 'zipcode.zip' | sed 's/<a data/\\n<a data/g' | grep -Po '(?<=href=\")[^\"]*(?=\")'\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing Jupyter variables to shell\n",
    "\n",
    "We can write a python loop to download each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files[:3]: #download the first 3 files\n",
    "    ! wget {f}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deciphering the NBA stats API\n",
    "\n",
    "### In today's class we go through methods in R for this one, try search ballr by toddwschneider.\n",
    "\n",
    "NBA provides a nice website for all data related to the tornament: [http://stat.nba.com](http://stat.nba.com). For example, in order to navigate to the shooting records for Stephen Curry, you navigate their menus to get to here:\n",
    "\n",
    "> [http://stats.nba.com/player/201939/shooting/?Season=2016-17&SeasonType=Regular%20Season](http://stats.nba.com/player/201939/shooting/?Season=2016-17&SeasonType=Regular%20Season)\n",
    "\n",
    "Here, we see some information related to our choices:\n",
    "- Season: 2016-17\n",
    "- SeasonType: Regular Season ([%20 is character code for space](https://en.wikipedia.org/wiki/Percent-encoding#Character_data))\n",
    "- Player: 201939 (less obvious)\n",
    "\n",
    "This type of URL is using a [GET method](https://www.w3schools.com/tags/ref_httpmethods.asp). When your URLs are very long, it is usually passing a series of variables and values to the web page. There are tools such as this [online URL parser](https://www.freeformatter.com/url-parser-query-string-splitter.html). Try passing in the URL.\n",
    "\n",
    "Knowledge of how web sites work is useful for data science since there is so much interaction through the web."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
