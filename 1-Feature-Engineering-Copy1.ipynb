{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "*Author: Benjamin Bradshaw*\n",
    "\n",
    "A *huge* piece of whether or not an inferential or predictive project is successful is whether or not the correct information is included in the model. Often times when dealing with IoT data, the raw signal collected from a device is not appropriate for direct input into the model. For example, if we were interested in using step data on a given day to predict whether or not that day was recorded on a weekday or a weekend, including each minute's step count for that day would result in 1440 features (machine learnign verbiage for variables). Unless we had a large amount of data to learn from and fed the raw signal into a complex model such as a neural network (which is possible these days) that might not be th ebest approach. A more labor intensive approach in a data constrained environment might be to conduct what is known as *feature engineering*.\n",
    "\n",
    "*Feature engineering* consists of taking raw data inputs and transforming them into such a way that extracts more signal, or captures specific characteristics of the data that are important for the task at hand. Feature engineering is not easy- mostly because it requires creativity on the part of *you* the practitioner to deeply understand the problem you are trying to solve, and then engineer features that allow a machine learning model to capture those characteristics. A large part of the preliminary detective work required for successful feature engineering comes in the form of *exploratory data analysis* which is just a fancy word for looking at the data and determining what aspects are important to capture in order to successfully extract the signal pertaining to your project.\n",
    "\n",
    "This notebook will cover the following topics:\n",
    "- Using exploratory data analysis (EDA) to identify useful aspects of the data that assist in our analysis task\n",
    "- Engineer features that capture the patterns identified during EDA\n",
    "\n",
    "In order motivate these tasks we construct the following prediction task: Can we utilize the accelerometer data in conjuction with other data available through NHANES to differentiate data collected on a weekday compare to data collected on a weekend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning objectives\n",
    "\n",
    "By the time you work through this notebook you should be able to:\n",
    "- Understand the need for splitting our data into a training and testing set when implementing a classification task, as well as how to correctly split our data depending on the use case at hand\n",
    "- Use some of the basic libraries used in pythn for EDA including pandas, matplotlib, and seaborn\n",
    "- Build basic software that allows efficient scaling of data analysis\n",
    "- Understand how features may be extracted from raw accelerometer data for the purpose of a classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize\n",
    "\n",
    "Dependencies. . . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import utils # Utility functions containained in ./utils/\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.set_option('max.rows', 100)\n",
    "pd.set_option('max.columns', 100)\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# Change this location to the path where you would like your data saved to\n",
    "data_dir = '/Users/bbradshaw/nhanes/'\n",
    "\n",
    "# Path to hdf store we will create later\n",
    "hdf_path = 'nhanes_data.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide whether to use the full raw dataset\n",
    "# or the sample. THe raw makes the UCSB machines\n",
    "# explode, so unless you are using a beefier \n",
    "# machine I would recommend setting using_sample\n",
    "# to True\n",
    "\n",
    "using_sample = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned accelerometer data from last time\n",
    "if using_sample:\n",
    "    %time pax = pd.read_hdf(os.path.join(data_dir, hdf_path), 'pax_clean_sample')\n",
    "else:\n",
    "     %time pax = pd.read_hdf(os.path.join(data_dir, hdf_path), 'pax_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'pax' prefix on column names: it was getting annoying\n",
    "pax.columns = [x.split('pax')[1] if 'pax' in x else x for x in pax.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pax.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The need for a training and testing set\n",
    "\n",
    "Traditional statistics often times is concerned with creating *estimators* that are unbiased or perhaps consistent estimates of some true population parameter $\\theta$. In this setting it is common to \"fit\" an estimator (e.g. linear/logistic regression etc) to the *entire* sample of data. In this setting this choice makes sense, since we seek to minimize the difference between $\\theta$ and $\\hat{\\theta}$ (our estimated parameter). Certain estimators have guarantees about unbiasedness, and we maximize our statistical power when we use the entire sample to fit the model (think about what happens to the standard errors of the OLS coefficients as $n \\rightarrow \\infty$). However, at the end of the day an inferential analysis always suffers from doubt: apart from collecting a second (or third, or fourth) sample, we have no bullet proof way to check how robust our results are.\n",
    "\n",
    "In a *prediction* setting our goal is quite different. Given a set of inputs $X$ we want our model to do a \"good\" job of minimizing the \"difference\" between the actual label associated with that input $y$ and the predicted label the model produces $\\hat{y}$. Because this is our goal, we have a very powerful tool on our side to asses whether or not our model is \"good\". The tool is conceptually very simple and easy to understand: we will split our training set into two sets: a \"training\" set and a \"testing\" set. The training set will be used for all exploratory work, model training, model selection, hyperparameter tuning etc. The testing set will be set aside, completely quarantined from our development process, and only used once our model is entirely finished. At that point, we will use our model to compute predictions over the test set and we will use these predictions to assess just how good our model would have been \"out in the wild\" when making predictions on unseen examples.\n",
    "\n",
    "Constructing a test set is conceptually simple, but it is fraught with danger in implementation. How you construct this split requires careful forethought about the goal of the task, as well as attention to the details that might imperil the generalizeability of your model.\n",
    "\n",
    "In this section we will construct a train-test split of our dataset, walking through some of the common issues that you might want to consider when building a pipeline of your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a testing-training split\n",
    "\n",
    "Let's get into the details of creating a train-test split. First we need to decide what the classification use case is. We know we are trying to classify weekdays and weekend days, but do we want our model to generalize to *new unseen people* or do we want our model to generalize to *new unseen days* on the same people. There is a subtle distinction between those two cases. In the first case, we would want to make sure people observed in our training set are not observed in our test set in order to ensure we simulate the ability to generalize to new people. In the second case it's actually OK if the same people show up in both the training and testing splits: we are training the model to learn individual specific patterns and behaviors.\n",
    "\n",
    "For this analysis let's say our goal is option 1: generalize to new people. Since this is the case we need to ensure that days from people in our chosen training set do not also end up in our test set. We'll also want to ensure that the statistical properties of our training set match that of our test set as closely as possible. \n",
    "\n",
    "We'll start by taking a look at the demographic table found in NHANES. We'll then conduct the following steps:\n",
    "- Filter the demographics table to only include participants who also exist in the pax table\n",
    "- Conduct stratified sampling on age/gender/other important characteristics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the demographic dataset\n",
    "\n",
    "In order to create a proper train-test split we'll first do soem exploration of the NHANES demographic table. Let's go ahead and read it in from our hdf store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall in the last notebook we read this from the NHANES website\n",
    "demo_df = pd.read_hdf(os.path.join(data_dir, hdf_path), 'demographics_with_sample_weights')\n",
    "\n",
    "# Recast seqn to object type for joining later\n",
    "demo_df['seqn'] = demo_df.seqn.astype(str)\n",
    "\n",
    "# Only keep participants who also have physical activity data\n",
    "demo_df = demo_df[demo_df.seqn.isin(pax.seqn.unique())]\n",
    "\n",
    "# Peek inside\n",
    "demo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What in the world? What are all the cryptic column names?? Well, the CDC has chosen somewhat unhelpful names that map to demographic characteristics of participants. We *could* go to the website that lists the variable names and keep track of them. However, if we are clever there might be a better way. . . .The pandas library makes it easy to scrape tables via a url. All we need is the url where the table is located, as well as the index of the xml blob we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_metadata_url = 'https://wwwn.cdc.gov/nchs/nhanes/search/variablelist.aspx?Component=Demographics&CycleBeginYear=2005'\n",
    "idx = 1 # I looked up the blob I was interested in in advance\n",
    "\n",
    "# Create demographic metadata DataFrame\n",
    "demo_metadata = pd.read_html(demo_metadata_url)[idx]\n",
    "\n",
    "# Filter metadata to just include the demographics table\n",
    "demo_metadata = demo_metadata[demo_metadata['Data File Name']=='DEMO_D']\n",
    "\n",
    "# Peek inside\n",
    "demo_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meta table we just created gives us the mapping from column names in our raw data to human readable descriptions. Unfortunately it doesn't give us what the variable facto levels correspond to. For this we will need to go to [this site](https://wwwn.cdc.gov/nchs/nhanes/2005-2006/DEMO_D.htm) to parse out each variable of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map numeric gender attributes to human readable\n",
    "gender_factor_levels = {\n",
    "    1: 'male',\n",
    "    2: 'female'\n",
    "}\n",
    "\n",
    "# Map numeric ethnicity values to human readable\n",
    "race_factor_levels = {\n",
    "    1: 'mexican_american',\n",
    "    2: 'other_hispanic',\n",
    "    3: 'non_hispanic_white',\n",
    "    4: 'non_hispanic_black',\n",
    "    5: 'other_race'\n",
    "}\n",
    "\n",
    "# Map in school ethnicity values to human readable\n",
    "school_factor_levels = {\n",
    "    1: 'in_school',\n",
    "    2: 'on_vacation_from_school',\n",
    "    3: 'between_grades',\n",
    "    -1: 'unknown'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some quick summary plots on age, gender and school status, since these seem like a good set of variables to stratify on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df.ridageyr.hist()\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we will definitely want to bin age and stratify given that weekend behavior may vary extensively between age brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode missing values to something we can map a value to\n",
    "demo_df['dmdschol'] = demo_df.dmdschol.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the distribution of school vs not school\n",
    "# My hypothesis here is that kids in school have much different sleep patterns\n",
    "# than those who aren't in school\n",
    "demo_df.dmdschol.map(school_factor_levels).value_counts().sort_values().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of male/female\n",
    "demo_df.riagendr.map(gender_factor_levels).value_counts().sort_values().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the train-test split\n",
    "\n",
    "In this section we will actually implement our train-test split with stratification. We will first stratify our sample by (1) age bin, (2) gender, and (3) school status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create age bins\n",
    "age_bins = [x*10 for x in range(10)]\n",
    "# Create a new variable that designates an age in years to an age bin\n",
    "demo_df['age_bin'] = pd.cut(demo_df.ridageyr, bins=age_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df.age_bin.value_counts().sort_index().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify our test proportion\n",
    "test_frac = 0.2\n",
    "\n",
    "# Conduct random stratified sampling and get a set of test ids\n",
    "test_ids = demo_df.groupby(['riagendr', 'dmdschol', 'age_bin'])\n",
    "test_ids = test_ids.apply(lambda df: df.sample(frac=test_frac)).seqn.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check everything worked out\n",
    "test_frac == (len(test_ids) / demo_df.seqn.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, extract train ids\n",
    "train_ids = demo_df[~demo_df.seqn.isin(test_ids)].seqn.unique()\n",
    "\n",
    "# QC check\n",
    "(1-test_frac) == len(train_ids) / demo_df.seqn.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One last sanity check\n",
    "len(set(train_ids).intersection(set(test_ids))) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a set of disjoint train and test ids, we can return to the activity data in order to construct a train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our training set\n",
    "train_pax = pax.merge(\n",
    "    demo_df.loc[demo_df.seqn.isin(train_ids), ['seqn']],\n",
    "    how='inner',\n",
    "    on='seqn'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our testing set\n",
    "test_pax = pax.merge(\n",
    "    demo_df.loc[demo_df.seqn.isin(test_ids), ['seqn']],\n",
    "    how='inner',\n",
    "    on='seqn'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the distribution of coverage over days seem reasonable\n",
    "# between train and test?\n",
    "train_pax.groupby('day').seqn.nunique() / len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pax.groupby('day').seqn.nunique() / len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building useful features\n",
    "\n",
    "In this section we are going to dive into the meat of engineering features using the raw physical activity data that will be used as inputs into our weekday-weekend classifier. Although it might initially be suprising, there is quite a bit of useful information that can extracted from the minute level into day level features. The first step in feature engineering is seeing what facets of your data correspond to the outcome of interest. In order to do that, we will begin with some exploratory data analysis (EDA).\n",
    "\n",
    "Note that in the physical activity dataset day of week is encoded as 1 => Sunday, 2 => Monday, . . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our target variable map\n",
    "weekend_map = {x: 1 if (x==1 or x==7) else 0 for x in range(1, 8)}\n",
    "\n",
    "# Map weekday variable to binary outcome\n",
    "train_pax['is_weekend'] = train_pax.day.map(weekend_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a very basic first pass, let's just look at some high level aggregates over days to see if we can observe differences between weekend and week days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day level summary statistics computed over minute level steps\n",
    "daily_aggs = train_pax.groupby(['seqn', 'day']).agg({x: ['mean', 'std', 'max'] for x in ['step', 'inten']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset columns\n",
    "agg_cols = ['seqn', 'day', 'steps_mean', 'steps_std', 'steps_max', 'inten_mean', 'inten_std', 'inten_max']\n",
    "daily_aggs = daily_aggs.reset_index()\n",
    "daily_aggs.columns = agg_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_aggs['is_weekend'] = daily_aggs.day.map(weekend_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['steps_mean', 'steps_std', 'steps_max', 'inten_mean', 'inten_std', 'inten_max']\n",
    "\n",
    "for i, feat in enumerate(features):\n",
    "    plt.figure(i)\n",
    "    sns.barplot(y=feat, x='is_weekend', data=daily_aggs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that even with these very basic features there is some class discrimination happeing here. In general, people walk less on weekend than they do on weekdays: both averaging across minutes as well as choosing the maximum minute of the day. Let's look at the entire distribution of mean steps for both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day_type in [0, 1]:\n",
    "    sns.distplot(\n",
    "        daily_aggs.loc[(daily_aggs.is_weekend==day_type) & (~daily_aggs.steps_mean.isnull()), 'steps_mean']\n",
    "    )\n",
    "    plt.xlim((0, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day_type in [0, 1]:\n",
    "    sns.distplot(\n",
    "        daily_aggs.loc[(daily_aggs.is_weekend==day_type) & (~daily_aggs.steps_mean.isnull()), 'steps_max']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see there definitely is *some* class separation: it isn't great, but it's a start! We are going to need to get more creative with our feature engineering. For better or for worse, many machine learning problems (especially in healthcare) require domain knowledge. The same is true of this problem: we need to creatively think about what factors may discriminate between weekdays and weekends. Let's brainstorm a few features:\n",
    "- Index of first minute walked during the day\n",
    "- Index of last minute walked during the day\n",
    "- Max steps walked during a minute of the day\n",
    "- Sum of steps walked during the day\n",
    "- % of minutes during a day where steps walked > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_step_minute(s):\n",
    "    \"\"\"\n",
    "    Compute the first observed step index within a user-day.\n",
    "    \"\"\"\n",
    "    nonzero_step_idx = np.nonzero(s.values)[0]\n",
    "    if len(nonzero_step_idx) > 0:\n",
    "        return np.min(nonzero_step_idx)\n",
    "    return np.nan\n",
    "\n",
    "def last_step_minute(s):\n",
    "    \"\"\"\n",
    "    Compute the first observed step index within a user-day.\n",
    "    \"\"\"\n",
    "    nonzero_step_idx = np.nonzero(s.values)[0]\n",
    "    if len(nonzero_step_idx) > 0:\n",
    "        return np.max(nonzero_step_idx)\n",
    "    return np.nan\n",
    "\n",
    "def max_steps(s):\n",
    "    \"\"\"\n",
    "    Return the maximum steps walked in a one minute period during a day\n",
    "    \"\"\"\n",
    "    return s.max()\n",
    "\n",
    "def sum_steps(s):\n",
    "    \"\"\"\n",
    "    Return the maximum steps walked in a one minute period during a day\n",
    "    \"\"\"\n",
    "    return s.sum()\n",
    "\n",
    "def pct_nonzero_steps(s):\n",
    "    \"\"\"\n",
    "    Return the percent of days with steps > 0\n",
    "    \"\"\"\n",
    "    nonzero_step_idx = np.nonzero(s.values)[0]\n",
    "    if len(nonzero_step_idx) > 0:\n",
    "        return 100*(len(nonzero_step_idx) / len(s))\n",
    "    return np.nan\n",
    "\n",
    "def max_rolling_30(s):\n",
    "    \"\"\"Compute the maximum 30 minute rolling window sum during a day\"\"\"\n",
    "    return s.rolling(window=30, win_type='triang', min_periods=5).sum().max()\n",
    "\n",
    "def first_morning_step_minute(s):\n",
    "    \"\"\"Compute the first step post 4 am\"\"\"\n",
    "    first_allowable_idx = 60*4 # index corresponding to 4am\n",
    "    s[:first_allowable_idx] = 0\n",
    "    nonzero_step_idx = np.nonzero(s.values)[0]\n",
    "    if len(nonzero_step_idx) > 0:\n",
    "        return np.min(nonzero_step_idx)\n",
    "    return np.nan\n",
    "\n",
    "def feature_computer(df, nodes):\n",
    "    \"\"\"Compute all features in nodes over all user-days in df\"\"\"\n",
    "    features = df.groupby(['seqn', 'day']).agg({'step': nodes})\n",
    "    features.reset_index(inplace=True)\n",
    "    feat_names = [x[1] for x in features.columns[2:]] \n",
    "    features.columns = ['seqn', 'day'] + feat_names\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of features we want to compute\n",
    "feature_nodes = [\n",
    "    first_step_minute,\n",
    "    last_step_minute,\n",
    "    max_steps,\n",
    "    sum_steps,\n",
    "    pct_nonzero_steps,\n",
    "    max_rolling_30,\n",
    "    first_morning_step_minute\n",
    "]\n",
    "\n",
    "# This takes a few seconds to compute\n",
    "train_features = feature_computer(train_pax, feature_nodes)\n",
    "test_features = feature_computer(test_pax, feature_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features['is_weekend'] = train_features.day.map(weekend_map)\n",
    "test_features['is_weekend'] = test_features.day.map(weekend_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['first_step_minute', 'last_step_minute', 'max_steps', 'sum_steps', 'pct_nonzero_steps', 'max_rolling_30', 'first_morning_step_minute']\n",
    "\n",
    "for feat in features:\n",
    "    plt.figure()\n",
    "    plt.title(feat)\n",
    "    for day_type in [0, 1]:\n",
    "        sns.distplot(\n",
    "            train_features.loc[\n",
    "                (train_features.is_weekend==day_type) & \n",
    "                (~train_features[feat].isnull()), feat\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these features look promising! Specifically first step minute is interesting: it corresponds to when people are waking up in the morning and our intuition tells us that people wake up later on the weekends. It's nice to see that the data supports our prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining Datasets\n",
    "\n",
    "Now that we have built a few promising features, let's add in the demographic features. In order to do that we need to *join* them in. We have already showed you a few joins in action, but now we'll explain a bit more what's going on under the hood. To do this we'll use the following datasets:\n",
    "\n",
    "- Selected participant demographics\n",
    "- Physical activity features computed above\n",
    "\n",
    "There is a 1:1 correspondence between these two tables: specifically each row in both has a unique ```seqn``` value that is also found in the other table. For this join, we will do what is known as an *inner join*. This means that we will specify a join key that exists in both sets, and *only* join those keys that exist in the intersection of the two key sets. For more information on the different types of joins check out [this resource](https://www.w3schools.com/sql/sql_join.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the following columns:\n",
    "keep_demo_cols = {'seqn': 'seqn', 'riagendr': 'gender', 'dmdschol': 'currently_in_school', 'dmdhhsiz': 'household_size', 'ridageyr': 'age_in_years'}\n",
    "\n",
    "# Create a copy of the demo df\n",
    "demo_keep = demo_df[list(keep_demo_cols.keys())].copy()\n",
    "\n",
    "# Remap names into something not insane\n",
    "demo_keep.rename(columns=keep_demo_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new DataFrame with pax + demographics\n",
    "train_analysis_set = train_features.merge(\n",
    "    demo_keep,\n",
    "    on='seqn',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "test_analysis_set = test_features.merge(\n",
    "    demo_keep,\n",
    "    on='seqn',\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_analysis_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a bit more visualization in order to understand whether the features we have built do a nice job of class separation. We'll segment by both school status as well as gender and then look at the distribution of first morning step minute and last step minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in ['first_morning_step_minute', 'last_step_minute']:\n",
    "    plt.figure()\n",
    "    sns.factorplot(\n",
    "        x='is_weekend',\n",
    "        y=feat,\n",
    "        hue='gender',\n",
    "        col='currently_in_school',\n",
    "        data=train_analysis_set,\n",
    "        kind='box',\n",
    "        size=4,\n",
    "        aspect=.7\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_factor_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how well feature combinations separate our classes in two dimensions\n",
    "\n",
    "# Add a string version of our label for plotting purposes\n",
    "train_analysis_set['weekend_str'] = train_analysis_set.is_weekend.map({1: 'weekend', 0: 'weekday'})\n",
    "\n",
    "# Create a copy of our data for plotting\n",
    "tmp = train_analysis_set.fillna(train_analysis_set.median())\n",
    "\n",
    "# Only select activity features\n",
    "act_feats = ['last_step_minute', 'max_steps', 'sum_steps', 'pct_nonzero_steps', 'max_rolling_30', 'first_morning_step_minute', 'weekend_str']\n",
    "\n",
    "# Pair plot\n",
    "g = sns.PairGrid(tmp[act_feats].fillna(tmp[act_feats].median()), hue='weekend_str')\n",
    "g = g.map_diag(plt.hist)\n",
    "g = g.map_offdiag(plt.scatter)\n",
    "g = g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above but segment by school status\n",
    "\n",
    "# Pair plot for only participants in school\n",
    "g = sns.PairGrid(tmp.loc[tmp.currently_in_school==1, act_feats], hue='weekend_str')\n",
    "g = g.map_diag(plt.hist)\n",
    "g = g.map_offdiag(plt.scatter)\n",
    "g = g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the class separation quality depends on the subgroup we choose for school status. None of the subgroups have amazing class separation, but in real world machine learning problems it's pretty rare to get spectacular separation in a two dimensional space. Real life isn't quite as straightforward as the iris dataset unfortunately.\n",
    "\n",
    "While we could spend more time designing features, it's often more fruitful to iterate quickly. Now that we have a few decent features let's move on to creating a baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_sample:\n",
    "    pass # Don't save the sampled features, we want everyone\n",
    "else:\n",
    "    # Save training set for later\n",
    "    train_analysis_set.to_hdf(os.path.join(data_dir, hdf_path), 'train_features')\n",
    "    # Save testing set for later\n",
    "    test_analysis_set.to_hdf(os.path.join(data_dir, hdf_path), 'test_features')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
