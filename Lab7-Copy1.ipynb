{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab7: Running EvidationDataScienceModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we will cover some of the basic sub-steps to run [EvidationDataScienceModule](https://github.com/evidation-health/EvidationDataScienceModule). \n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Road map:\n",
    "\n",
    "Setup: \n",
    "\n",
    "0. Open a terminal tab and navigate to `~/work/`.\n",
    "1. Clone repo: `git clone https://github.com/evidation-health/EvidationDataScienceModule.git`\n",
    "2. Using the Jupyter  UI navigate to `~/work/EvidationDataScienceModule/Notebooks/utils/` and open `pull_nhanes_data.sh`\n",
    "3. In  that file comment lines no. 16-20 in order to avoid moving the downloaded files to the root folder (this will leave data objects in the same location where `pull_nhanes_data.sh` is run). \n",
    "4. Go to the terminal and navigate to `~/work/EvidationDataScienceModule/`\n",
    "5. Type `./utils/pull_nhanes_data.sh` and press the return key to download data files.\n",
    "---\n",
    "Downloading dependencies:\n",
    "\n",
    "1. Using the Jupyter  UI navigate to `~/work/EvidationDataScienceModule/Notebooks/utils/` and open `setup_env.sh`.\n",
    "2. Comment out lines 7,10,16 in order to avoid creating a python local environment.\n",
    "3. Modify line 13 to: `pip install -r ~/work/EvidationDataScienceModule/requirements.txt` to indicate the absolute path of the main Evidation repo folder.\n",
    "3. Go to the terminal and navigate to `~/work/EvidationDataScienceModule/`\n",
    "4. Type `./utils/setup_env.sh` and press the return key to download all package dependencies. \n",
    "\n",
    "---\n",
    "\n",
    "Running notebook:\n",
    "\n",
    "- Open `EvidationDataScienceModule/notebooks/0-ETL-Munging-QC.ipynb`.\n",
    "- Update data folder path in the first code chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this location to the path where you would like your data saved to\n",
    "data_dir = '/home/jovyan/work/EvidationDataScienceModule/'\n",
    "\n",
    "# Path to hdf store we will create later\n",
    "hdf_path = '/home/jovyan/work/EvidationDataScienceModule/nhanes_data.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In `0-ETL-Munging-QC.ipynb` notebook we will actually start from the \"Read other NHANES tables directly from source\" section.\n",
    "- Try running the code chunk which contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.read_sas_write_hdf(source_paths, data_dir, 'nhanes.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may encounter this error: https://stackoverflow.com/questions/38203988/encoding-in-sas7dbat.\n",
    "- ONLY if you had this error (in my case I had that error on the UCSB Jupyterhub):\n",
    "    - Open `EvidationDataScienceModule/notebooks/utils/__init__.py` using the Jupyter UI and look for the  `read_sas_write_hdf()` function declaration. \n",
    "    - Replace the line `tmp = pd.read_sas(path)` (line no. 31) to `tmp = pd.read_sas(path,encoding='iso-8859-1')`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
